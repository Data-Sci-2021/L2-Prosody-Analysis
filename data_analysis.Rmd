---
title: "data_analysis"
author: "Miroo Lee"
date: "12/14/2021"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(stringr)
library(readr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(knitr)
library(car)
library(broom)
library(gridExtra)
library(effsize)#cohen.d()
opts_chunk$set(fig.path="/Users/miroolee/Documents/DataScience/L2-Prosody-Analysis/plots")
```

## Part 1. Cleaning the praat output  
After running a praat script that exports annotated information from Praat text grids, we get a txt file that needs cleaning. This document illustrates how I cleaned and prepared the data for the analysis.    

----------------------------------   

### 1. Determine the encoding   
I used a very handy guess_encoding function form readr package.  

```{r echo=TRUE, warning=FALSE}
wav_folder <- "/Users/miroolee/Documents/DataScience/L2-Prosody-Analysis/wav_SAMPLES"
dat_path <- paste(wav_folder, "/duration_results.txt", sep="")
guess_encoding(dat_path)
dat <- read_tsv(dat_path, locale=locale(encoding="UTF-16"))
```


### 2. Add proficiency level  
I united some parts from the previous PELIC output (1.3) to praat output 
```{r}
folder <- "/Users/miroolee/Documents/DataScience/L2-Prosody-Analysis"
lev_path <- paste(folder, "/KOR_mono.csv", sep="")
lev <- read.csv(lev_path)

lev1<-lev %>%
  unite(Filename, c("row_id", "anon_id")) %>%
  select (c(Filename, gender, level_id))

dat1 <- dat %>%
  left_join(lev1, dat, by="Filename")
```

### 3. Add list of words and their lexical stress info  
For this part, I made a separate document containing syllable structure and lexical stress information of all the words in the wav files [`wordList.csv`](wordList.csv) which can be found in my github repository. This information was handcoded by me, and therefore needs to be updated continuously as you add more wav files with new words. Obviously this is not optimal, and I hope to replace this document with some sort of dictionary later that contains syllable structure and stress information. 

Here I have three newly annotated wav files. I am combining the new words to my previous 'wordList.csv' file. 
```{r}
wdDat_path <- paste(folder, "/wordList.csv", sep="")
wdDat <- read.csv(wdDat_path)

dat2 <- dat1 %>%
  left_join(wdDat, by =c("SyllLabel" = "SyllLabel", "WordLabel" = "WordLabel"))

new_wdDat <- dat2 %>%
  filter(Filename=="21819_ea4"|Filename=="23027_ea4"|Filename=="24473_ea4") %>%
  distinct(WordLabel,SyllLabel, .keep_all=TRUE) #I think I can also use anti_join() but oh well.

write.csv(new_wdDat, 'new_wordList.csv')
```

Next step is to work on new_wordList.csv that does not have values in SyllCV, primary and secondary stress. This is the part that needs handcoding (until I figure out how to replace it with dictionary). For now, I will work with dat2.  


### 4. Specify syllables' positions in words and mark if stressed    
I added two new variables:  
__[SyllOrder]__ has with 3 levels: (wd) initial, medial and final.   
__[stress]__ has 2 levels: stressed, unstressed.   

There's an issue in the PrimaryStress coding. Now if syllable 1,2,3 are stressed (ex:USA), PrimaryStress value shows as 123. This would be shown as 'unstressed' in stress column. The number of this exception is not great, and we will move forward with the data as it is for now.  

```{r}
 dat3<-dat2 %>%
  select(-c(PitchMaxInPhone,...13)) %>%
  separate(SyllLabel, into = c("currentSyll", "entireSyll", sep ="_" )) %>%
  add_column(SyllOrder = "medial") %>%
  mutate (SyllOrder = case_when(
  currentSyll == "1" ~ "initial",
  currentSyll == entireSyll ~ "final",
  currentSyll < entireSyll ~ "medial")) %>%
  mutate (stress = case_when(
    currentSyll == PrimaryStress ~ "stressed",
    currentSyll != PrimaryStress ~ "unstressed"))
```

### 5. Normalize segment durations    
I added one new variable:
__[normedPhoneDur]__ which is calculated by dividing raw duration by the syllable duration. This was used specifically for voiceless stops VOT and voiceless fricatives to account for speech rate.  
```{r}
dat4 <- dat3 %>%
  mutate(normedPhoneDur = PhoneDuration/SyllDuration )
```

### 6. Clean the phone labels     
Removed numbers from [PrecedingPhone].[PhoneLabel].[FollowingPhone].  
```{r}
 dat5 <- dat4 %>% 
  mutate_at("PrecedingPhone", str_replace, "[12345]_", "") %>%
  mutate_at("PhoneLabel", str_replace, "[12345]_", "") %>%
  mutate_at("FollowingPhone", str_replace, "[12345]_", "")
```

### 7. Checking for level_id and add Proficiency
Before moving forward with data manipulation, I did a brief status check of the data. The following code revealed one file **17107_hb4** did not have level_id information. This seems to have been caused by either the wav file naming error or the file info error at the PELIC_speech_compiled.csv. Either way, for now I am manually inserting the level_id for **17107_hb4** as 5, based on the other file naming convention of the same student at the level 5.
```{r}
dat5%>%
  group_by(Filename,level_id)%>%
  count()

dat5<-dat5%>%
  mutate(level_id=ifelse(Filename=="17107_hb4",5,level_id))%>%
  mutate(Proficiency=ifelse(level_id=="3"|level_id=="4","intermediate","advanced"))

dat5%>%
  group_by(SyllOrder,currentSyll,entireSyll)%>%
  count()

dat5<-dat5%>% #removing an erroroneous row
  subset(!entireSyll=="new")
```

### 8. Assigning unique index on each syllable  
Note that what I am interested in is how consonant and vowel in the same syllable are affected by the boundary effect. In order to look at this, I need to have preceding pause level per syllable. At this point, I have PrecedingPhone information which tells us the information about pause per segment, but not per syllable. Therefore, taking PrecedingPhone alone will not give us the information we need to code preceding pause per syllable. (ex. for the case of #CV with pause level 1, C will be coded as having a pause level 1 but V will be coded as pause level 0. What we need instead is both C and V to being coded as having pause level 1).

To do this, I will first create **syll_index** using the combinations of Filename + currentSyll + SyllDuration + WordLabel +WordDuration + SyllCV + SyllOrder. This gives me 4810 syllables. 
1. **syll_index_data**: dataframe group_by above factors.
2. **syll_id**: index column for each unique syllable based on the combinations of above factors. 

```{r}
syll_index_dat <- dat5 %>%
  group_by(Filename,currentSyll,SyllDuration,WordLabel,WordDuration,SyllCV,SyllOrder) %>%
  count() %>% 
  rowid_to_column("syll_id") %>%
  mutate()
```

I will then add the syll_id column from syll_index_dat to my original data by using left join. 
```{r}
dat6 <- left_join(syll_index_dat, dat5, by=c("Filename","currentSyll","SyllDuration","WordLabel","WordDuration","SyllCV","SyllOrder"))
```

Next, I will create seg_id column, which will be used for joining the data.
```{r}
dat6 %>%
  rowid_to_column("seg_id") %>%
  mutate()
```
  
What we need now is to find any syllable that has at least one L, M, or S in precedingPhone and mark the preceding pause before syllable as L, M, or S. To do this, I will create a new column **PrecedingPause_syll** (preceding pause per syllable).  
I will then join these **PrecedingPause_syll** to my original data. After joining the data, I will find the rest of the syllables that are not marked for pause (L,M,S), and mark them for 0 pause. 
```{r}
preP_L_dat <- dat6 %>%
  group_by(syll_id) %>%
  filter(any(PrecedingPhone == "L")) %>% #changing L to 3
  mutate(PrecedingPause_syll = 3)

preP_M_dat <- dat6 %>%
  group_by(syll_id) %>%
  filter(any(PrecedingPhone == "M")) %>% #changing M to 2
  mutate(PrecedingPause_syll = 2)  
 
preP_S_dat <- dat6%>%
  group_by(syll_id) %>%
  filter(any(PrecedingPhone=="S")) %>% #changing S to 1
  mutate(PrecedingPause_syll = 1)  

preP_total_dat <- bind_rows(preP_L_dat, preP_M_dat, preP_S_dat) %>%
  select("seg_id","syll_id","PrecedingPause_syll") #2065

dat7 <- left_join(dat6, preP_total_dat, by=c("seg_id","syll_id"))

dat7 <- dat7 %>%
  replace_na(list(PrecedingPause_syll = 0))
```
I will update following pause later. 

### 9. Assign Preceding Pause Level at the segment level. 
Here I am adding two new columns;  

**PrecedingPause_seg** tells us the level of preceding pause for assessing DIS(Domain-Initial Strengthening) effects before segments.  
**FollowingPause_seg** tells us the level of following pause for assessing DFL(Domin-Final Lengthening) effects before segments.


```{r}
dat7 <- dat7 %>%
  mutate(PrecedingPause_syll = factor(PrecedingPause_syll, levels = c(0,1,2,3))) %>%
  mutate(Proficiency = factor(Proficiency, levels = c("intermediate","advanced"))) %>%
  mutate(stress = factor(stress, levels = c("unstressed","stressed"))) %>%
mutate(IsVowel = case_when(
    IsVowel == "yes" ~ "vowel",
    IsVowel == "no" ~ "consonant"))
```
  
```{r ERROR DO NOT RUN}
  #mutate(FollowingPause_seg = case_when(
  #  FollowingPhone == "L" ~ "3",
  #  FollowingPhone == "M" ~ "2",
  #  FollowingPhone == "S" ~ "1")) %>%
  #replace_na(list(FollowingPause_seg = 0))%>%
  #mutate(FollowingPause_seg=fct_relevel(FollowingPause_seg,c("0","1","2","3")))
```

### 10. Select CVC,CV syllable 
Here I am filtering CV and CVC only. Because VOT durations are differentially enhanced depending on a voicing feature(shorter for voiced, longer for voiceless), I only looked at voiceless consonants. For a similar reason, I only looked at single consonant onset, rather than looking at syllable onset with double or more consonants (ex: steam).   
```{r}
dat8 <- dat7 %>%
  filter(SyllCV %in% c("CV","CVC"))

dat8 %>%
  group_by(Proficiency,PrecedingPause_syll,IsVowel)%>%
  count()

dat8 %>%
  group_by(Proficiency,PrecedingPause_syll,IsVowel)%>%
  count()%>%
  ggplot(aes(x=Proficiency, y=n,fill=as.factor(PrecedingPause_syll)))+
  geom_bar(stat='identity',position="fill")
```

### 11. Select vowels and consonants 
Select voiceless consonants and monothong vowel. 
```{r}
dat9 <- dat8 %>%
  filter(PhoneLabel %in% c("V","t_vot","k_vot","p_vot","f","s","ð","ʃ"))
```

## Part 2. Descriptive Statistics
For the analysis of DIS, I am only looking at CV and CVC. Note that the main interests in this analysis is any durational changes (**PhoneDuration**,**normedPhoneDur**) in vowels and voiceless consonants as a function of **stress**, **PrecedingPause/FollowingPause**, and **Proficiency**.  

Here I am doing several descriptive statistics to get a better picture of the data at hand. 

Syllable level DIS effects on consonants 
```{r}
dat9 %>%
  filter(PhoneLabel %in% c("t_vot","k_vot","p_vot","f","s","ð","ʃ"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(PhoneDuration), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Domain-initial effects on voiceless consonants")

dis_c_raw <-dat9 %>%
  filter(PhoneLabel %in% c("t_vot","k_vot","p_vot","f","s","ð","ʃ"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(PhoneDuration), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Consonant duration in #CV,#CVC")+
  facet_wrap(~Proficiency)+
  theme(legend.position="bottom")


dis_c_norm <- dat9 %>%
  filter(PhoneLabel %in% c("t_vot","k_vot","p_vot","f","s","ð","ʃ"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(normedPhoneDur), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Consonant% in #CV,#CVC")+
  facet_wrap(~Proficiency)+
  theme(legend.position="bottom")


grid.arrange(dis_c_raw, dis_c_norm, nrow = 1)
```

Syllable level DIS effects on vowels 
```{r}
dat9 %>%
  filter(PhoneLabel %in% c("V"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(PhoneDuration), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Domain-initial effects on vowels")

dis_v_raw<-dat9 %>%
  filter(PhoneLabel %in% c("V"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(PhoneDuration), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Vowel duration in #CV,#CVC")+
  facet_wrap(~Proficiency)+
  theme(legend.position="bottom")

dat9 %>%
  filter(PhoneLabel %in% c("V"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(normedPhoneDur), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Vowel% in #CV & #CVC")

dis_v_norm<-dat9 %>%
  filter(PhoneLabel %in% c("V"))%>%
  ggplot(aes(as.factor(PrecedingPause_syll),log(normedPhoneDur), color=stress))+
  geom_boxplot(outlier.shape=NA)+
  xlab('Preceding pause level')+
  ggtitle("Vowel% in #CV,#CVC")+
 facet_wrap(~Proficiency)+
  theme(legend.position="bottom")
```

### 12. Assessing DIS and DFL effects
 
1. **PhoneDuration** between **SyllOrder** initial vs. medial  

2. **PhoneDuration** of **initial SyllOrder** as a function of **PrecedingPause** 



## Part 3. Statistical Analysis on DIS on CV
I tested how the word-initial syllable's consonants(C)' and vowels(V)' durations are affected by the preceding __1.pause duration(0-3)__, the presence of __2.lexical stress(str vs unstr)__, and the learners' __3.proficiency level(3 vs.5)__. As for the dependent variable, **log([PhoneDuration])** was used for vowels and **[normedPhonDur]** for consonants.


### 13. w/interaction; V in wd-initial
For the analysis, I am interested in how proficiency level interact with stress and boundary effects. Therefore, the model I would be ultimately interested in would include pause,stress,and proficiency. But to understand the data better, I will start with a model that only includes pause and stress.

**Model for intermediate level**
```{r}
v_md1 = lmer(log(PhoneDuration)~PrecedingPause_syll*stress+(1|WordLabel)+(1|Filename), data = dat9 %>% filter(Proficiency=="intermediate",PhoneLabel=="V"))
summary(v_md1) 
vif(v_md1)
coef(v_md1)
library(MuMIn)
r.squaredGLMM(v_md1)

tibble(fitted = fitted(v_md1),
       residuals = residuals(v_md1)) %>% 
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point()+ 
  geom_smooth()

tibble(fitted = fitted(v_md1),
       residuals = residuals(v_md1)) %>% 
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point()+ 
  geom_smooth()
```
v_md1 interpretation: For the intermediate data, V was shortened after pauses. The degree of shortening was the largest for pause level 1 and smallest for pause level 3.  There was also a trend of lengthening in stressed condition. stress and pause further interacted in that vowels were lengthened when it was in both stressed and pause level 1 and 2 conditions.  

**Model for advanced level**
```{r}
v_md2 = lmer(log(PhoneDuration)~PrecedingPause_syll*stress+(1|WordLabel)+(1|Filename), data = dat9 %>% filter(Proficiency=="advanced",PhoneLabel=="V"))
summary(v_md2) # V was lengthened by stress.
vif(v_md2)
coef(v_md2)

tibble(fitted = fitted(v_md2),
       residuals = residuals(v_md2)) %>% 
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point()+ 
  geom_smooth()
```
There was only stress -induced lengthening effect.  

**Model with pause,stress,proficiency**
```{r}
v_md3 = lmer(log(PhoneDuration)~PrecedingPause_syll*stress*Proficiency+(1|WordLabel)+(1|Filename), data = dat9 %>% filter(PhoneLabel=="V"))
summary(v_md3) # V was lengthened by stress.

tibble(fitted = fitted(v_md3),
       residuals = residuals(v_md3)) %>% 
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point()+ 
  geom_smooth()

vif(v_md3)
```
shortening effect of pause 1 and 2. Level 1 has the biggest shortening effect. Vowels were shorter at the advanced level (but this could have been due to an increased speech rate). Interaction between pause and stress in that vowels increased in pause level 1 and stressed condition. (similar trend for pause level 2). There was also an interaction between pause and proficiency in that vowel lengths in all pause levels increased (or a trend) at the advanced level. In other words, pause-induced shortening from intermediate level significantly mediated at the advanced level. Interestingly, pause+stress boost effect was also significantly medigated at the advanced level. 



```{r}
v_md4 = lmer(log(normedPhoneDur)~PrecedingPause_syll*stress*Proficiency+(1|WordLabel)+(1|Filename), data = dat9 %>% filter(PhoneLabel=="V"))
summary(v_md4) # V was lengthened by stress.

tibble(fitted = fitted(v_md4),
       residuals = residuals(v_md4)) %>% 
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point()+ 
  geom_smooth()

vif(v_md4)
```
  
  
### 14. w/ interaction; C in wd-initial  
```{r}
c_md1 = lmer(log(PhoneDuration)~PrecedingPause_syll*stress*Proficiency+(1|WordLabel)+(1|Filename), data=dat9 %>% filter(PhoneLabel %in% c("t_vot","k_vot","p_vot","f","s","ð","ʃ")))
summary(c_md1)





c_md2 = lmer(log(normedPhoneDur)~PrecedingPause_syll*stress*Proficiency+(1|WordLabel)+(1|Filename), data=dat9 %>% filter(PhoneLabel %in% c("t_vot","k_vot","p_vot","f","s","ð","ʃ")))
summary(c_md2)
```
