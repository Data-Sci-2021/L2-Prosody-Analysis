---
title: "ELI speech corpus note"
author: "Miroo Lee"
date: "10/27/2021"
output: github_markdown
---

```{r setup, include=FALSE}
library(tidyverse)
library(stringr)
setwd("/Users/miroolee/ELI speech data/")
dat <- read_csv("PELIC_speech_compiled.csv") 
```


Check the number of speakers by L1.
The top three L1s are Arabic, Chinese, and Korean.
The top three levels are 3,4, and 5.
```{r}
table(dat$L1, dat$level_id)
```


### Finding korean speakers who enrolled for level 3-5.
Note that the results will show Korean speakers who were enrolled for level 3-5 or more. The output data may include files from level 2 if speakers were enrolled for 2,3,4,and 5. But all speakers will have minimum of 3,4,5 level data. 
```{r}
kor_3levels <- dat %>%
  filter (L1=="Korean" & level_id!="2") %>%
  distinct (anon_id, level_id) %>%
  count (anon_id) %>%
  filter (n==3) %>%
  inner_join (dat, by="anon_id") %>%
  rename(row_id = 3)
print(kor_3levels)
```

### Finding the 2min monologues from Recorded Speech Activity (from Speaking classes) from level 3 and 5. What we are looking for is file_info_id 1. 
```{r}
kor_dat <- kor_3levels %>%
  filter (level_id=="3"|level_id=="5") %>%
  filter (file_info_id=="1") %>%
print(kor_dat)

write.csv(kor_dat, 'korean_monologues_lv13.csv')
```

### Finding the corresponding txt transcriptions for the audio files. 
This actually created a dataframe with 33 variables
```{r}
kor_txt <- kor_3levels %>%
  inner_join (kor_dat, by = c("row_id" = "corresponding_file")) %>%
  select(-ends_with("y"))

write.csv(kor_txt, 'korean_monologues_lv13_transcriptions.csv')

```


  